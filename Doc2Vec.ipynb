{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- CLASSIFICATION USING ONLY WINE DESCRIPTIONS ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aleks\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# NLP Libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# One-Hot Encoding\n",
    "from nltk.corpus import wordnet as wn\n",
    "from string import punctuation as punc\n",
    "\n",
    "# Document to Vector Embedding \n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "# Saving to file\n",
    "import pickle\n",
    "\n",
    "# Miscellaneous Functions\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_tree import *\n",
    "from helper_functions import *\n",
    "from pruning import *\n",
    "from random_forest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save/load objects to/from file\n",
    "def save_obj(obj, name):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "class Switch(dict):\n",
    "    def __getitem__(self, item):\n",
    "        for key in self.keys():                   # iterate over the intervals\n",
    "            if item in key:                       # if the argument is part of that interval\n",
    "                return super().__getitem__(key)   # return its associated value\n",
    "        raise KeyError(item)                      # if not in any interval, raise KeyError\n",
    "        \n",
    "switch = Switch({\n",
    "    range(80, 88): 'Average',\n",
    "    range(88, 94): 'Good',\n",
    "    range(94, 101): 'Excellent'\n",
    "})\n",
    "\n",
    "def switch_value(i):\n",
    "    return switch[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  price  province  \\\n",
       "1  Portugal   15.0     Douro   \n",
       "2        US   14.0    Oregon   \n",
       "3        US   13.0  Michigan   \n",
       "\n",
       "                                               title         variety  \\\n",
       "1      Quinta dos Avidagos 2011 Avidagos Red (Douro)  Portuguese Red   \n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)      Pinot Gris   \n",
       "3  St. Julian 2013 Reserve Late Harvest Riesling ...        Riesling   \n",
       "\n",
       "                winery                                        description  \\\n",
       "1  Quinta dos Avidagos  This is ripe and fruity, a wine that is smooth...   \n",
       "2            Rainstorm  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           St. Julian  Pineapple rind, lemon pith and orange blossom ...   \n",
       "\n",
       "   points  \n",
       "1      87  \n",
       "2      87  \n",
       "3      87  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winemag-data_130k.csv', index_col=0)\n",
    "df = df.drop(['designation','region_1','region_2','taster_name','taster_twitter_handle'], axis=1)\n",
    "df = df.reindex(columns = ['country', 'price', 'province', 'title', 'variety', 'winery', 'description', 'points'])\n",
    "df = df.dropna()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good         67023\n",
      "Average      48232\n",
      "Excellent     5660\n",
      "Name: points, dtype: int64 \n",
      "\n",
      " 120915  rows\n"
     ]
    }
   ],
   "source": [
    "df['points'] = df['points'].apply(switch_value)\n",
    "print(df.points.value_counts(), '\\n\\n', len(df), ' rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- BEGINNING OF DOC2VEC ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  price  province  \\\n",
       "1  Portugal   15.0     Douro   \n",
       "2        US   14.0    Oregon   \n",
       "3        US   13.0  Michigan   \n",
       "\n",
       "                                               title         variety  \\\n",
       "1      Quinta dos Avidagos 2011 Avidagos Red (Douro)  Portuguese Red   \n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)      Pinot Gris   \n",
       "3  St. Julian 2013 Reserve Late Harvest Riesling ...        Riesling   \n",
       "\n",
       "                winery                                        description  \\\n",
       "1  Quinta dos Avidagos  This is ripe and fruity, a wine that is smooth...   \n",
       "2            Rainstorm  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           St. Julian  Pineapple rind, lemon pith and orange blossom ...   \n",
       "\n",
       "    points  \n",
       "1  Average  \n",
       "2  Average  \n",
       "3  Average  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df\n",
    "filtered_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    #Replace and breaks with regular spaces\n",
    "    norm_text = norm_text.replace('<br />',' ')\n",
    "    norm_text = norm_text.replace(', ',' ')\n",
    "    #Use regex to pad all punctuation with spaces on both sides\n",
    "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_text)\n",
    "    norm_text = norm_text.lower()\n",
    "    return norm_text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in tokenizer.tokenize(text): #nltk.word_tokenize(sentence):\n",
    "            if len(word)<2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "def process_text(text):\n",
    "    token_list_orig = tokenize_text(text)\n",
    "    token_list = []\n",
    "    for token_orig in token_list_orig:\n",
    "        token = lemmatizer.lemmatize(normalize_text(token_orig), pos='a') #pos = 'a' --> adjective\n",
    "        if token.isdigit()==False and token not in token_list:\n",
    "            token_list.append(token)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         This is ripe and fruity, a wine that is smooth...\n",
      "2         Tart and snappy, the flavors of lime flesh and...\n",
      "3         Pineapple rind, lemon pith and orange blossom ...\n",
      "4         Much like the regular bottling from 2012, this...\n",
      "5         Blackberry and raspberry aromas show a typical...\n",
      "                                ...                        \n",
      "129966    Notes of honeysuckle and cantaloupe sweeten th...\n",
      "129967    Citation is given as much as a decade of bottl...\n",
      "129968    Well-drained gravel soil gives this wine its c...\n",
      "129969    A dry style of Pinot Gris, this is crisp with ...\n",
      "129970    Big, rich and off-dry, this is powered by inte...\n",
      "Name: description, Length: 120915, dtype: object\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that's\", \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'will', 'yet', 'therefore']\n",
    "\n",
    "# Dictionary of elements and their respective counts\n",
    "counts = Counter(STOPWORDS)\n",
    "# Print elements which have 2 or more instances.\n",
    "for i in counts:\n",
    "    if counts[i] > 1:\n",
    "        print(i, counts[i])\n",
    "        \n",
    "print(filtered_df['description'])   \n",
    "filtered_df['description']=filtered_df['description'].transform(process_text)\n",
    "filtered_df['description']=filtered_df['description'].transform(lambda x: [word for word in x if word not in set(STOPWORDS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faint', 'scent', 'red', 'cherry', 'greets', 'nose', 'also', 'makes', 'brief', 'appearance', 'fresh', 'clean', 'rather', 'light', 'body', 'slightly', 'rustic', 'honest', 'straightforward', 'drink', 'soon']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['description'].iloc[104450]) #Example of processed description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Useful Bigrams or Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(filtered_df['description'], min_count=3, delimiter=b' ')\n",
    "trigram = Phrases(bigram[filtered_df['description']], min_count=3, delimiter=b' ')\n",
    "\n",
    "for i in range(len(filtered_df['description'])):\n",
    "    description = filtered_df['description'].iloc[i]\n",
    "    bigrams_list = [b for b in bigram[description] if b.count(' ') == 1]\n",
    "    trigrams_list = [t for t in trigram[bigram[description]] if t.count(' ') == 2]\n",
    "    \n",
    "    # Add identified bigrams to the tokenized description\n",
    "    if len(bigrams_list) != 0:\n",
    "        #print(bigrams_list)\n",
    "        for sequence in bigrams_list:\n",
    "            if sequence not in description:\n",
    "                filtered_df['description'].iloc[i].append(sequence)\n",
    "\n",
    "    if len(trigrams_list) !=0:\n",
    "        #print(trigrams_list)\n",
    "        for sequence in trigrams_list:\n",
    "             if sequence not in description:\n",
    "                filtered_df['description'].iloc[i].append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faint', 'scent', 'red', 'cherry', 'greets', 'nose', 'also', 'makes', 'brief', 'appearance', 'fresh', 'clean', 'rather', 'light', 'body', 'slightly', 'rustic', 'honest', 'straightforward', 'drink', 'soon', 'greets nose', 'brief appearance', 'drink soon']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['description'].iloc[104450]) #Example of processed description with bi(tri)grams added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "train, test = train_test_split(filtered_df, test_size=0.3)\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['description'], tags=[r.points]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['description'], tags=[r.points]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         ([ripe, fruity, wine, smooth, still, structure...\n",
      "3         ([pineapple, rind, lemon, pith, orange, blosso...\n",
      "4         ([much, like, regular, bottling, comes, across...\n",
      "6         ([bright, informal, red, opens, aromas, candie...\n",
      "7         ([dry, restrained, wine, offers, spice, profus...\n",
      "                                ...                        \n",
      "129966    ([notes, honeysuckle, cantaloupe, sweeten, del...\n",
      "129967    ([citation, given, much, decade, bottle, age, ...\n",
      "129968    ([well, drained, gravel, soil, gives, wine, cr...\n",
      "129969    ([dry, style, pinot, gris, crisp, some, acidit...\n",
      "129970    ([big, rich, dry, powered, intense, spiciness,...\n",
      "Length: 84641, dtype: object \n",
      "\n",
      " 90112     ([riverbend, vineyard, estate, fielding, hills...\n",
      "15686     ([sweet, rounded, very, satisfying, wine, pack...\n",
      "3512      ([opens, enticing, scents, white, spring, flow...\n",
      "104450    ([winery, best, barrel, bottling, chardonnay, ...\n",
      "38883     ([nicely, put, together, totally, generic, sen...\n",
      "                                ...                        \n",
      "31042     ([central, otago, pinot, noir, doesn, come, al...\n",
      "19841     ([some, richness, heft, separate, wine, pack, ...\n",
      "73420     ([foundation, truffled, earth, forest, floor, ...\n",
      "60167     ([heat, power, emerge, immediately, nose, slig...\n",
      "28353     ([yellow, color, subdued, aromas, apple, squas...\n",
      "Length: 36274, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_tagged, '\\n\\n', test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['winery', 'best', 'barrel', 'bottling', 'chardonnay', 'excels', 'fronts', 'showing', 'lemon', 'peels', 'browned', 'butter', 'creamy', 'lily', 'pan', 'seared', 'apples', 'light', 'crisp', 'savory', 'nose', 'mouthfeel', 'rich', 'decorated', 'zesty', 'line', 'salty', 'acidity', 'cuts', 'curd', 'flavors', 'altogether', 'mouthwatering', 'perfect', 'seaside', 'meal', 'lemon peels', 'browned butter', 'pan seared', 'acidity cuts', 'pan seared apples'], tags=['Excellent'])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged[104450] #Example of tagged description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Doc2Vec Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2568758.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2495852.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2819397.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2424766.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2173322.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2233329.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2233371.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2333504.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 1732001.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2459250.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2496256.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2424799.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2069993.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2424849.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2170518.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2357429.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2496115.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 1768137.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2140316.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2424832.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2233329.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2233413.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2496273.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 1697459.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2496115.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2496186.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2122009.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 1805674.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2020512.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 1973681.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 84641/84641 [00:00<00:00, 2293687.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Build a Distributed Bag of Words model\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, window=6, alpha=0.1, negative=0, hs=1, min_count=1, sample=0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=10)\n",
    "    model_dbow.alpha-=0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(filtered_df, 'filtered_df_BI(TRI)GRAMS_ADDED')\n",
    "save_obj(model_dbow, 'Doc2VecModel_dim300_BI(TRI)BIGRAMS_ADDED')\n",
    "save_obj(train_tagged, 'train_tagged_BI(TRI)GRAMS_ADDED')\n",
    "save_obj(test_tagged, 'test_tagged_BI(TRI)GRAMS_ADDED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Read of Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = load_obj('filtered_df_BI(TRI)GRAMS_ADDED')\n",
    "model_dbow = load_obj('Doc2VecModel_dim300_BI(TRI)BIGRAMS_ADDED')\n",
    "train_tagged = load_obj('train_tagged_BI(TRI)GRAMS_ADDED')\n",
    "test_tagged = load_obj('test_tagged_BI(TRI)GRAMS_ADDED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector(model, tagged_docs):\n",
    "    sentences = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sentences])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = build_vector(model_dbow, train_tagged)\n",
    "y_test, X_test = build_vector(model_dbow, test_tagged)\n",
    "\n",
    "y_test, y_train = np.asarray(y_test), np.asarray(y_train)\n",
    "X_test, X_train = np.asarray(X_test), np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features:\n",
      " [[-0.18063109 -0.09168802  0.05263169 ... -0.53402215  0.09448549\n",
      "   0.8700811 ]\n",
      " [ 0.01169075 -0.17287932 -0.5011579  ...  0.68881804 -0.24040882\n",
      "  -0.16493876]\n",
      " [ 0.29427034 -0.42070842  0.8691367  ... -0.60931605  0.43962625\n",
      "  -0.4169078 ]\n",
      " ...\n",
      " [-0.3071592   1.0296812  -0.5473156  ...  0.19299982 -0.15332144\n",
      "   0.36165422]\n",
      " [ 0.8991018  -0.55979055  0.24753436 ... -0.3449637  -0.19222908\n",
      "  -0.3669207 ]\n",
      " [ 0.44568652 -0.28273207 -0.6249972  ... -0.07680467  0.27394786\n",
      "   0.29635316]] \n",
      "\n",
      "Testing features:\n",
      " [[ 0.19210516 -0.18950948  0.39476228 ...  0.42772606  0.26536658\n",
      "   0.1264891 ]\n",
      " [ 0.07479941 -0.3259339  -0.19050281 ...  0.13997473  0.10704373\n",
      "   0.5419218 ]\n",
      " [-1.0062314   0.7475895  -0.5165186  ... -0.47335842  0.11224923\n",
      "   0.18396878]\n",
      " ...\n",
      " [-0.15938194  0.59519124 -0.4622667  ... -0.36517146 -0.35467997\n",
      "   0.17865384]\n",
      " [ 0.6753725   0.28228733  0.70300704 ...  0.20463043  0.32598522\n",
      "   0.24419516]\n",
      " [ 0.07302083 -0.09450662 -0.11047351 ...  0.22620979 -0.16857931\n",
      "  -0.2981271 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Training features:\\n', X_train, '\\n\\nTesting features:\\n', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Training features shape:  (84641, 300) \n",
      "Testing features shape:  (36274, 300)\n",
      "Training labels shape:  (84641,) \n",
      "Testing labels shape:  (36274,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test), type(y_test), type(X_train), type(y_train))\n",
    "print('Training features shape: ', X_train.shape, '\\nTesting features shape: ', X_test.shape)\n",
    "print('Training labels shape: ', y_train.shape, '\\nTesting labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels:\n",
      " ['Average' 'Average' 'Average' ... 'Good' 'Good' 'Good'] \n",
      "\n",
      "Testing labels:\n",
      " ['Good' 'Good' 'Good' ... 'Average' 'Average' 'Good']\n"
     ]
    }
   ],
   "source": [
    "print('Training labels:\\n', y_train, '\\n\\nTesting labels:\\n', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- END OF DOC2VEC ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- CLASSIFICATION ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training & Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = X_train, y_train.reshape(X_train.shape[0], 1) #X_train_variety.reshape(X_train.shape[0], 1), y_train.reshape(X_train.shape[0], 1)\n",
    "ts = X_test, y_test.reshape(X_test.shape[0], 1)    #X_test_variety.reshape(X_test.shape[0], 1), y_test.reshape(X_test.shape[0], 1)\n",
    "TRAIN = np.hstack(tr)\n",
    "TEST = np.hstack(ts)\n",
    "\n",
    "# Columns = [0, 1, ..., 48, 49]: One for each dimension of the document vectors\n",
    "columns = list(range(X_train.shape[1]))\n",
    "for i in range(len(columns)):\n",
    "    columns[i]=str(columns[i])\n",
    "columns.append('label')\n",
    "\n",
    "TRAIN_df = pd.DataFrame(TRAIN, columns=columns)\n",
    "TEST_df = pd.DataFrame(TEST, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.18063109</td>\n",
       "      <td>-0.09168802</td>\n",
       "      <td>0.052631687</td>\n",
       "      <td>-0.043893747</td>\n",
       "      <td>-0.34156874</td>\n",
       "      <td>0.259521</td>\n",
       "      <td>-0.45582443</td>\n",
       "      <td>-0.12794867</td>\n",
       "      <td>-0.034824472</td>\n",
       "      <td>0.07642121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6598472</td>\n",
       "      <td>0.056489363</td>\n",
       "      <td>0.50765467</td>\n",
       "      <td>-0.0833376</td>\n",
       "      <td>0.121211246</td>\n",
       "      <td>-0.105902575</td>\n",
       "      <td>-0.53402215</td>\n",
       "      <td>0.09448549</td>\n",
       "      <td>0.8700811</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0116907535</td>\n",
       "      <td>-0.17287932</td>\n",
       "      <td>-0.5011579</td>\n",
       "      <td>0.13859753</td>\n",
       "      <td>0.14515564</td>\n",
       "      <td>-0.35263827</td>\n",
       "      <td>0.07524348</td>\n",
       "      <td>-0.36220583</td>\n",
       "      <td>-0.40334728</td>\n",
       "      <td>-0.063262105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562625</td>\n",
       "      <td>-0.74703544</td>\n",
       "      <td>0.51362324</td>\n",
       "      <td>-0.33625287</td>\n",
       "      <td>-0.15952665</td>\n",
       "      <td>0.17526025</td>\n",
       "      <td>0.68881804</td>\n",
       "      <td>-0.24040882</td>\n",
       "      <td>-0.16493876</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.29427034</td>\n",
       "      <td>-0.42070842</td>\n",
       "      <td>0.8691367</td>\n",
       "      <td>-0.10208137</td>\n",
       "      <td>0.4608331</td>\n",
       "      <td>0.4718892</td>\n",
       "      <td>0.369057</td>\n",
       "      <td>0.31387204</td>\n",
       "      <td>0.8788484</td>\n",
       "      <td>-0.20462957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39358893</td>\n",
       "      <td>-0.6458911</td>\n",
       "      <td>-0.38713202</td>\n",
       "      <td>0.31280017</td>\n",
       "      <td>-0.927837</td>\n",
       "      <td>-0.585237</td>\n",
       "      <td>-0.60931605</td>\n",
       "      <td>0.43962625</td>\n",
       "      <td>-0.4169078</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035120413</td>\n",
       "      <td>0.1886508</td>\n",
       "      <td>0.09495963</td>\n",
       "      <td>0.005063279</td>\n",
       "      <td>-0.3539823</td>\n",
       "      <td>0.12063132</td>\n",
       "      <td>-0.057408195</td>\n",
       "      <td>0.105671465</td>\n",
       "      <td>0.10154272</td>\n",
       "      <td>-0.14498043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110404305</td>\n",
       "      <td>0.75273836</td>\n",
       "      <td>-0.057315934</td>\n",
       "      <td>0.48987964</td>\n",
       "      <td>0.22876121</td>\n",
       "      <td>-0.07744057</td>\n",
       "      <td>-0.4477602</td>\n",
       "      <td>0.11079756</td>\n",
       "      <td>-0.18533617</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.47292754</td>\n",
       "      <td>-0.05432705</td>\n",
       "      <td>0.40259084</td>\n",
       "      <td>0.2410157</td>\n",
       "      <td>0.098396845</td>\n",
       "      <td>0.20488013</td>\n",
       "      <td>-0.58484787</td>\n",
       "      <td>0.02871327</td>\n",
       "      <td>-0.5234438</td>\n",
       "      <td>-0.015211833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4958639</td>\n",
       "      <td>-0.32117414</td>\n",
       "      <td>-0.17192987</td>\n",
       "      <td>0.020348648</td>\n",
       "      <td>-0.36109847</td>\n",
       "      <td>-0.28892007</td>\n",
       "      <td>0.059827104</td>\n",
       "      <td>0.16394907</td>\n",
       "      <td>0.11296543</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2             3            4  \\\n",
       "0   -0.18063109  -0.09168802  0.052631687  -0.043893747  -0.34156874   \n",
       "1  0.0116907535  -0.17287932   -0.5011579    0.13859753   0.14515564   \n",
       "2    0.29427034  -0.42070842    0.8691367   -0.10208137    0.4608331   \n",
       "3   0.035120413    0.1886508   0.09495963   0.005063279   -0.3539823   \n",
       "4   -0.47292754  -0.05432705   0.40259084     0.2410157  0.098396845   \n",
       "\n",
       "             5             6            7             8             9  ...  \\\n",
       "0     0.259521   -0.45582443  -0.12794867  -0.034824472    0.07642121  ...   \n",
       "1  -0.35263827    0.07524348  -0.36220583   -0.40334728  -0.063262105  ...   \n",
       "2    0.4718892      0.369057   0.31387204     0.8788484   -0.20462957  ...   \n",
       "3   0.12063132  -0.057408195  0.105671465    0.10154272   -0.14498043  ...   \n",
       "4   0.20488013   -0.58484787   0.02871327    -0.5234438  -0.015211833  ...   \n",
       "\n",
       "            291          292           293          294          295  \\\n",
       "0     0.6598472  0.056489363    0.50765467   -0.0833376  0.121211246   \n",
       "1     -0.562625  -0.74703544    0.51362324  -0.33625287  -0.15952665   \n",
       "2   -0.39358893   -0.6458911   -0.38713202   0.31280017    -0.927837   \n",
       "3  -0.110404305   0.75273836  -0.057315934   0.48987964   0.22876121   \n",
       "4     0.4958639  -0.32117414   -0.17192987  0.020348648  -0.36109847   \n",
       "\n",
       "            296          297          298          299    label  \n",
       "0  -0.105902575  -0.53402215   0.09448549    0.8700811  Average  \n",
       "1    0.17526025   0.68881804  -0.24040882  -0.16493876  Average  \n",
       "2     -0.585237  -0.60931605   0.43962625   -0.4169078  Average  \n",
       "3   -0.07744057   -0.4477602   0.11079756  -0.18533617  Average  \n",
       "4   -0.28892007  0.059827104   0.16394907   0.11296543  Average  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=5\n",
    "\n",
    "# We select k random samples from our dataset, and divide them into num_folds disjoint sets of equal length\n",
    "indices = TRAIN_df.index.tolist()\n",
    "cv_dataset_indices = random.sample(population=indices, k=1000)\n",
    "cv_dataset = TRAIN_df.loc[cv_dataset_indices]\n",
    "cv_dataset = np.asarray(cv_dataset)\n",
    "cv = cross_validation_fold_split(dataset=cv_dataset, folds = num_folds)\n",
    "cv = np.asarray(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Decision Tree (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then train our model(s) on num_folds-1 of the sets and evaluate on the final set (giving every set a chance to be the evaluation set)\n",
    "print(\"TREE CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=TRAIN_df, test_set_index=i)\n",
    "    cv_tree = decision_tree_algorithm(df=df_cv_train, ml_task='classification', max_depth=10)\n",
    "    \n",
    "    j = random_exclude(excluded=i, range_list=range(num_folds))\n",
    "    _, df_val = cross_validation_train_test_split(cv_set=cv, df=TRAIN_df, test_set_index=j)\n",
    "    cv_tree_pruned = post_pruning(cv_tree, df_cv_train, df_val, ml_task=\"classification\")\n",
    "    \n",
    "    accuracy = calculate_accuracy(df_cv_test, cv_tree)\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('Cross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CROSS VALIDATION RESULTS\n",
      "Cross Validation Split Shape:  (5, 200, 301)\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=TRAIN_df, test_set_index=i)\n",
    "    cv_forest = multiprocessor_random_forest_algorithm(train_df=df_cv_train, n_trees=50, n_bootstrap=375, n_features=9999, \n",
    "                                                tree_max_depth=10, ml_task='classification')\n",
    "    accuracy, predictions = calculate_forest_accuracy(df_cv_test, cv_forest)\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "cv_accuracy = total_accuracy/numf_folds\n",
    "print('\\n\\nCross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
