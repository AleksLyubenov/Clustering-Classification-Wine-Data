{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- CLASSIFYING WINE TYPES BASED ON WINEMAKER'S DESCRIPTIONS --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aleks\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# NLP Libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# One-Hot Encoding\n",
    "from nltk.corpus import wordnet as wn\n",
    "from string import punctuation as punc\n",
    "\n",
    "# Document to Vector Embedding \n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "# Saving to file\n",
    "import pickle\n",
    "\n",
    "# Miscellaneous Functions\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_tree import *\n",
    "from helper_functions import *\n",
    "from pruning import *\n",
    "from random_forest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save/load objects to/from file\n",
    "def save_obj(obj, name):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "class Switch(dict):\n",
    "    def __getitem__(self, item):\n",
    "        for key in self.keys():                   # iterate over the intervals\n",
    "            if item in key:                       # if the argument is part of that interval\n",
    "                return super().__getitem__(key)   # return its associated value\n",
    "        raise KeyError(item)                      # if not in any interval, raise KeyError\n",
    "\n",
    "switch = Switch({\n",
    "    \"White Wines\": 0,\n",
    "    \"Red Wines\": 1\n",
    "})\n",
    "\n",
    "\n",
    "def switch_value(i):\n",
    "    return switch[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>abv</th>\n",
       "      <th>year</th>\n",
       "      <th>PriceRetail</th>\n",
       "      <th>Appellation_Region_Name</th>\n",
       "      <th>Varietal_Name</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milbrandt Traditions Merlot 2007</td>\n",
       "      <td>14.2</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>Red Wines</td>\n",
       "      <td>Our 2007 Traditions Merlot features grapes fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MacLaren Drouthy Neebors Syrah 2009</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>California</td>\n",
       "      <td>Syrah/Shiraz</td>\n",
       "      <td>Red Wines</td>\n",
       "      <td>Deep Purple color. Layered aromatics: Black Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cliff Lede Poetry Stags Leap District Cabernet...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>125.00</td>\n",
       "      <td>California</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Red Wines</td>\n",
       "      <td>Beautiful bottle-aged aromas are revealing the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tenuta di Biserno Campo di Sasso Insoglio del ...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Other Red Blends</td>\n",
       "      <td>Red Wines</td>\n",
       "      <td>Insoglio del Cinghiale is the foundation wine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gordon Brothers Cabernet Sauvignon 2010</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>26.99</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Red Wines</td>\n",
       "      <td>Black cherry and cranberry, vanilla roasting o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name   abv    year  \\\n",
       "0                   Milbrandt Traditions Merlot 2007  14.2  2007.0   \n",
       "1                MacLaren Drouthy Neebors Syrah 2009  14.0  2009.0   \n",
       "2  Cliff Lede Poetry Stags Leap District Cabernet...  14.5  2001.0   \n",
       "3  Tenuta di Biserno Campo di Sasso Insoglio del ...  14.5  2007.0   \n",
       "4            Gordon Brothers Cabernet Sauvignon 2010  13.8  2010.0   \n",
       "\n",
       "   PriceRetail Appellation_Region_Name       Varietal_Name      label  \\\n",
       "0        14.99              Washington              Merlot  Red Wines   \n",
       "1        35.00              California        Syrah/Shiraz  Red Wines   \n",
       "2       125.00              California  Cabernet Sauvignon  Red Wines   \n",
       "3        34.00                   Italy    Other Red Blends  Red Wines   \n",
       "4        26.99              Washington  Cabernet Sauvignon  Red Wines   \n",
       "\n",
       "                                         description  \n",
       "0  Our 2007 Traditions Merlot features grapes fro...  \n",
       "1  Deep Purple color. Layered aromatics: Black Ra...  \n",
       "2  Beautiful bottle-aged aromas are revealing the...  \n",
       "3  Insoglio del Cinghiale is the foundation wine ...  \n",
       "4  Black cherry and cranberry, vanilla roasting o...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./DATASETS/winemaker_data.csv', encoding='latin-1')\n",
    "df = df.rename(columns={\"Varietal_WineType_Name\": \"label\", \"Winemakers_Notes\":\"description\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1000\n",
      "0    1000\n",
      "Name: label, dtype: int64 \n",
      "\n",
      " 2000  rows\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'].apply(switch_value)\n",
    "print(df.label.value_counts(), '\\n\\n', len(df), ' rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- BEGINNING OF DOC2VEC ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>abv</th>\n",
       "      <th>year</th>\n",
       "      <th>PriceRetail</th>\n",
       "      <th>Appellation_Region_Name</th>\n",
       "      <th>Varietal_Name</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milbrandt Traditions Merlot 2007</td>\n",
       "      <td>14.2</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2007 Traditions Merlot features grapes fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MacLaren Drouthy Neebors Syrah 2009</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>California</td>\n",
       "      <td>Syrah/Shiraz</td>\n",
       "      <td>1</td>\n",
       "      <td>Deep Purple color. Layered aromatics: Black Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cliff Lede Poetry Stags Leap District Cabernet...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>125.00</td>\n",
       "      <td>California</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>1</td>\n",
       "      <td>Beautiful bottle-aged aromas are revealing the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name   abv    year  \\\n",
       "0                   Milbrandt Traditions Merlot 2007  14.2  2007.0   \n",
       "1                MacLaren Drouthy Neebors Syrah 2009  14.0  2009.0   \n",
       "2  Cliff Lede Poetry Stags Leap District Cabernet...  14.5  2001.0   \n",
       "\n",
       "   PriceRetail Appellation_Region_Name       Varietal_Name  label  \\\n",
       "0        14.99              Washington              Merlot      1   \n",
       "1        35.00              California        Syrah/Shiraz      1   \n",
       "2       125.00              California  Cabernet Sauvignon      1   \n",
       "\n",
       "                                         description  \n",
       "0  Our 2007 Traditions Merlot features grapes fro...  \n",
       "1  Deep Purple color. Layered aromatics: Black Ra...  \n",
       "2  Beautiful bottle-aged aromas are revealing the...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df\n",
    "filtered_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    #Replace and breaks with regular spaces\n",
    "    norm_text = norm_text.replace('<br />',' ')\n",
    "    norm_text = norm_text.replace(', ',' ')\n",
    "    #Use regex to pad all punctuation with spaces on both sides\n",
    "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_text)\n",
    "    norm_text = norm_text.lower()\n",
    "    return norm_text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in tokenizer.tokenize(text): #nltk.word_tokenize(sentence):\n",
    "            if len(word)<2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "def process_text(text):\n",
    "    token_list_orig = tokenize_text(text)\n",
    "    token_list = []\n",
    "    for token_orig in token_list_orig:\n",
    "        token = lemmatizer.lemmatize(normalize_text(token_orig), pos='a') #pos = 'a' --> adjective\n",
    "        if token.isdigit()==False and token not in token_list:\n",
    "            token_list.append(token)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Our 2007 Traditions Merlot features grapes fro...\n",
      "1       Deep Purple color. Layered aromatics: Black Ra...\n",
      "2       Beautiful bottle-aged aromas are revealing the...\n",
      "3       Insoglio del Cinghiale is the foundation wine ...\n",
      "4       Black cherry and cranberry, vanilla roasting o...\n",
      "                              ...                        \n",
      "1995    Our 2009 Estate Chardonnay is refreshing and c...\n",
      "1996    Delle Venezie, Italy The Tre Venezie region is...\n",
      "1997    Grown on the hillside above the Santa Maria Be...\n",
      "1998    Framed by a light lemony acidity and vibrant m...\n",
      "1999    Because of the popularity and demand of our Dr...\n",
      "Name: description, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that's\", \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'will', 'yet', 'therefore']\n",
    "\n",
    "# Dictionary of elements and their respective counts\n",
    "counts = Counter(STOPWORDS)\n",
    "# Print elements which have 2 or more instances.\n",
    "for i in counts:\n",
    "    if counts[i] > 1:\n",
    "        print(i, counts[i])\n",
    "        \n",
    "print(filtered_df['description'])   \n",
    "filtered_df['description']=filtered_df['description'].transform(process_text)\n",
    "filtered_df['description']=filtered_df['description'].transform(lambda x: [word for word in x if word not in set(STOPWORDS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some', 'best', 'chardonnays', 'washington', 'state', 'grown', 'slightly', 'cool', 'growing', 'conditions', 'yakima', 'valley', 'northern', 'latitudes', 'columbia', 'schmitt', 'vineyard', 'provides', 'nice', 'tropical', 'fruit', 'evergreen', 'latitude', 'river', 'contributes', 'crisp', 'acidity', 'minerality', 'elegantly', 'expressive', 'chardonnay', 'offers', 'enticing', 'mix', 'flint', 'asian', 'pear', 'vibrant', 'structure', 'wine', 'finely', 'balanced', 'richness', 'adding', 'complexity', 'clean', 'lingering', 'finish']\n"
     ]
    }
   ],
   "source": [
    "index = random.randint(0, len(filtered_df))\n",
    "print(filtered_df['description'].iloc[index]) #Example of processed description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Useful Bigrams or Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(filtered_df['description'], min_count=3, delimiter=b' ')\n",
    "trigram = Phrases(bigram[filtered_df['description']], min_count=3, delimiter=b' ')\n",
    "\n",
    "for i in range(len(filtered_df['description'])):\n",
    "    description = filtered_df['description'].iloc[i]\n",
    "    bigrams_list = [b for b in bigram[description] if b.count(' ') == 1]\n",
    "    trigrams_list = [t for t in trigram[bigram[description]] if t.count(' ') == 2]\n",
    "    \n",
    "    # Add identified bigrams to the tokenized description\n",
    "    if len(bigrams_list) != 0:\n",
    "        #print(bigrams_list)\n",
    "        for sequence in bigrams_list:\n",
    "            if sequence not in description:\n",
    "                filtered_df['description'].iloc[i].append(sequence)\n",
    "    '''\n",
    "    if len(trigrams_list) !=0:\n",
    "        #print(trigrams_list)\n",
    "        for sequence in trigrams_list:\n",
    "             if sequence not in description:\n",
    "                filtered_df['description'].iloc[i].append(sequence)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some', 'best', 'chardonnays', 'washington', 'state', 'grown', 'slightly', 'cool', 'growing', 'conditions', 'yakima', 'valley', 'northern', 'latitudes', 'columbia', 'schmitt', 'vineyard', 'provides', 'nice', 'tropical', 'fruit', 'evergreen', 'latitude', 'river', 'contributes', 'crisp', 'acidity', 'minerality', 'elegantly', 'expressive', 'chardonnay', 'offers', 'enticing', 'mix', 'flint', 'asian', 'pear', 'vibrant', 'structure', 'wine', 'finely', 'balanced', 'richness', 'adding', 'complexity', 'clean', 'lingering', 'finish', 'washington state', 'cool growing', 'tropical fruit', 'crisp acidity', 'chardonnay offers', 'asian pear', 'adding complexity', 'lingering finish']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['description'].iloc[index]) #Example of processed description with bi(tri)grams added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "train, test = train_test_split(filtered_df, test_size=0.3)\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['description'], tags=[r.label]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['description'], tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       ([traditions, merlot, features, grapes, differ...\n",
      "2       ([beautiful, bottle, aged, aromas, revealing, ...\n",
      "5       ([bright, violet, red, color, extends, primary...\n",
      "8       ([crozes, hermitage, le, clos, cuvee, deep, ru...\n",
      "9       ([dark, night, absolutely, explosive, nose, ri...\n",
      "                              ...                        \n",
      "1993    ([guenoc, lake, county, sauvignon, blanc, made...\n",
      "1995    ([estate, chardonnay, refreshing, crisp, flora...\n",
      "1996    ([delle, venezie, italy, tre, region, made, th...\n",
      "1997    ([grown, hillside, santa, maria, bench, barbar...\n",
      "1999    ([popularity, demand, dry, riesling, sweet, th...\n",
      "Length: 1400, dtype: object \n",
      "\n",
      " 1309    ([ghost, pines, chardonnay, possesses, express...\n",
      "228     ([almira, los, dos, bright, cherry, red, viole...\n",
      "51      ([vineyard, sources, old, vine, zinfandel, blu...\n",
      "1518    ([bright, clear, appearance, sauvignon, blanc,...\n",
      "563     ([illustration, offers, intense, aromatics, bl...\n",
      "                              ...                        \n",
      "1064    ([wine, aromas, fresh, lime, juice, stone, fru...\n",
      "1102    ([light, scents, citrus, floral, flavors, ripe...\n",
      "1373    ([chardonnay, elegant, expression, vintage, wa...\n",
      "403     ([liante, wind, levant, gusts, throughout, adr...\n",
      "745     ([number, wine, com, knights, valley, very, sp...\n",
      "Length: 600, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_tagged, '\\n\\n', test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['dark', 'purple', 'color', 'generous', 'aromas', 'currants', 'blackberry', 'licorice', 'chocolate', 'black', 'olive', 'espresso', 'vanilla', 'wine', 'round', 'full', 'palate', 'forward', 'fruit', 'great', 'structure', 'balanced', 'acid', 'tannins', 'decant', 'youth', 'enjoy', 'next', 'years', 'blend', 'cabernet', 'sauvignon', 'malbec', 'franc', 'petit', 'verdot', 'purple color', 'black olive', 'next years', 'blend cabernet', 'malbec franc', 'petit verdot'], tags=[1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged[index] #Example of tagged description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Doc2Vec Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 853120.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1404118.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1406136.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1404118.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1401438.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1404118.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1405126.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 467555.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1404454.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 467592.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1403447.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1402777.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1403112.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1400435.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1408159.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 702227.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1395443.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1404454.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1420422.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 699883.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1401103.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1401772.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1401772.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 702563.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 704164.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1402442.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 1404454.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1400/1400 [00:00<00:00, 701891.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Build a Distributed Bag of Words model\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=50, window=5, alpha=0.1, negative=0, hs=1, min_count=1, sample=0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha-=0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(filtered_df, 'Doc2Vec_Set2_filtered_df_BIGRAMS_ADDED')\n",
    "save_obj(model_dbow, 'Doc2Vec_Set2_dim50_BIBIGRAMS_ADDED')\n",
    "save_obj(train_tagged, 'Doc2Vec_Set2_train_tagged_BIGRAMS_ADDED')\n",
    "save_obj(test_tagged, 'Doc2Vec_Set2_test_tagged_BIGRAMS_ADDED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Read of Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = load_obj('Doc2Vec_Set2_filtered_df_BIGRAMS_ADDED')\n",
    "model_dbow = load_obj('Doc2Vec_Set2_dim50_BIBIGRAMS_ADDED')\n",
    "train_tagged = load_obj('Doc2Vec_Set2_train_tagged_BIGRAMS_ADDED')\n",
    "test_tagged = load_obj('Doc2Vec_Set2_test_tagged_BIGRAMS_ADDED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector(model, tagged_docs):\n",
    "    sentences = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sentences])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = build_vector(model_dbow, train_tagged)\n",
    "y_test, X_test = build_vector(model_dbow, test_tagged)\n",
    "\n",
    "y_test, y_train = np.asarray(y_test), np.asarray(y_train)\n",
    "X_test, X_train = np.asarray(X_test), np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features:\n",
      " [[ 0.5243982  -0.03275125  0.05669038 ...  1.0344319  -0.596706\n",
      "   0.20215616]\n",
      " [-0.10164765 -0.04866321 -0.10057602 ...  0.7482713   1.3736737\n",
      "  -0.16044329]\n",
      " [ 1.5054115   0.26774165  0.5422134  ... -0.00344261  0.18010773\n",
      "   1.9383588 ]\n",
      " ...\n",
      " [ 0.53142196  0.8812689   0.15873995 ... -1.3987981  -0.40616184\n",
      "   0.4942059 ]\n",
      " [-0.2781031  -0.66414523 -0.20700526 ... -0.12378209  0.14133808\n",
      "   0.15886061]\n",
      " [ 0.75472564 -1.5386854  -0.48001447 ... -0.02232955 -1.1940879\n",
      "   0.64506173]] \n",
      "\n",
      "Testing features:\n",
      " [[-0.23453255 -0.60255736 -0.27274948 ... -0.06704514 -1.2434884\n",
      "   0.16366035]\n",
      " [ 0.09970373  0.43510538  0.0881969  ...  0.44452217 -0.22727357\n",
      "   1.1556609 ]\n",
      " [-0.01916254  0.60981625 -0.35722786 ...  0.45252728 -0.75482935\n",
      "  -0.252179  ]\n",
      " ...\n",
      " [-0.12269566  0.17664967  0.801761   ... -0.02225018 -0.5020351\n",
      "   0.29009673]\n",
      " [ 0.30077466 -0.19669685 -0.04734763 ...  0.20968905  0.5462311\n",
      "   0.6462368 ]\n",
      " [ 0.5650323   0.24459806 -0.02922523 ...  0.02188571  0.4730297\n",
      "   0.40061057]]\n"
     ]
    }
   ],
   "source": [
    "print('Training features:\\n', X_train, '\\n\\nTesting features:\\n', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Training features shape:  (1400, 50) \n",
      "Testing features shape:  (600, 50)\n",
      "Training labels shape:  (1400,) \n",
      "Testing labels shape:  (600,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test), type(y_test), type(X_train), type(y_train))\n",
    "print('Training features shape: ', X_train.shape, '\\nTesting features shape: ', X_test.shape)\n",
    "print('Training labels shape: ', y_train.shape, '\\nTesting labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels:\n",
      " [1 1 1 ... 0 0 0] \n",
      "\n",
      "Testing labels:\n",
      " [0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0\n",
      " 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0\n",
      " 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0\n",
      " 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0\n",
      " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1\n",
      " 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1\n",
      " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('Training labels:\\n', y_train, '\\n\\nTesting labels:\\n', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- END OF DOC2VEC ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- CLASSIFICATION ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training & Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = X_train, y_train.reshape(X_train.shape[0], 1) #X_train_variety.reshape(X_train.shape[0], 1), y_train.reshape(X_train.shape[0], 1)\n",
    "ts = X_test, y_test.reshape(X_test.shape[0], 1)    #X_test_variety.reshape(X_test.shape[0], 1), y_test.reshape(X_test.shape[0], 1)\n",
    "TRAIN = np.hstack(tr)\n",
    "TEST = np.hstack(ts)\n",
    "\n",
    "# Columns = [0, 1, ..., 48, 49]: One for each dimension of the document vectors\n",
    "columns = list(range(X_train.shape[1]))\n",
    "for i in range(len(columns)):\n",
    "    columns[i]=str(columns[i])\n",
    "columns.append('label')\n",
    "\n",
    "TRAIN_df = pd.DataFrame(TRAIN, columns=columns)\n",
    "TEST_df = pd.DataFrame(TEST, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524398</td>\n",
       "      <td>-0.032751</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>-0.920059</td>\n",
       "      <td>-0.421100</td>\n",
       "      <td>-0.203994</td>\n",
       "      <td>0.476724</td>\n",
       "      <td>0.570324</td>\n",
       "      <td>-0.183935</td>\n",
       "      <td>2.084440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365105</td>\n",
       "      <td>0.222436</td>\n",
       "      <td>1.318043</td>\n",
       "      <td>0.170131</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>-1.363862</td>\n",
       "      <td>1.034432</td>\n",
       "      <td>-0.596706</td>\n",
       "      <td>0.202156</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.101648</td>\n",
       "      <td>-0.048663</td>\n",
       "      <td>-0.100576</td>\n",
       "      <td>1.407300</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.121042</td>\n",
       "      <td>0.093383</td>\n",
       "      <td>-1.260965</td>\n",
       "      <td>1.189414</td>\n",
       "      <td>0.048460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>-0.424213</td>\n",
       "      <td>-0.030207</td>\n",
       "      <td>-0.585183</td>\n",
       "      <td>-0.329262</td>\n",
       "      <td>0.881722</td>\n",
       "      <td>0.748271</td>\n",
       "      <td>1.373674</td>\n",
       "      <td>-0.160443</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.505412</td>\n",
       "      <td>0.267742</td>\n",
       "      <td>0.542213</td>\n",
       "      <td>-1.005325</td>\n",
       "      <td>-0.179881</td>\n",
       "      <td>0.468256</td>\n",
       "      <td>-0.317871</td>\n",
       "      <td>-0.495346</td>\n",
       "      <td>1.144418</td>\n",
       "      <td>-0.016699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120182</td>\n",
       "      <td>-0.258227</td>\n",
       "      <td>0.045762</td>\n",
       "      <td>0.319787</td>\n",
       "      <td>-0.150069</td>\n",
       "      <td>1.334856</td>\n",
       "      <td>-0.003443</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>1.938359</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.266760</td>\n",
       "      <td>0.871653</td>\n",
       "      <td>-1.397439</td>\n",
       "      <td>-1.590761</td>\n",
       "      <td>-0.449100</td>\n",
       "      <td>-0.310976</td>\n",
       "      <td>0.696647</td>\n",
       "      <td>-0.399794</td>\n",
       "      <td>1.280667</td>\n",
       "      <td>0.093377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171234</td>\n",
       "      <td>-0.750394</td>\n",
       "      <td>-0.122897</td>\n",
       "      <td>-1.706450</td>\n",
       "      <td>0.137792</td>\n",
       "      <td>-0.465734</td>\n",
       "      <td>-0.720827</td>\n",
       "      <td>-0.416541</td>\n",
       "      <td>-0.985605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406107</td>\n",
       "      <td>-0.119848</td>\n",
       "      <td>-0.459487</td>\n",
       "      <td>-0.564603</td>\n",
       "      <td>-0.869797</td>\n",
       "      <td>-0.120177</td>\n",
       "      <td>0.230116</td>\n",
       "      <td>-0.301367</td>\n",
       "      <td>-0.126521</td>\n",
       "      <td>-0.148975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728755</td>\n",
       "      <td>-0.240772</td>\n",
       "      <td>-0.423331</td>\n",
       "      <td>-0.604241</td>\n",
       "      <td>0.539562</td>\n",
       "      <td>0.392587</td>\n",
       "      <td>0.577998</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>0.374064</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.524398 -0.032751  0.056690 -0.920059 -0.421100 -0.203994  0.476724   \n",
       "1 -0.101648 -0.048663 -0.100576  1.407300  0.003519  0.121042  0.093383   \n",
       "2  1.505412  0.267742  0.542213 -1.005325 -0.179881  0.468256 -0.317871   \n",
       "3 -0.266760  0.871653 -1.397439 -1.590761 -0.449100 -0.310976  0.696647   \n",
       "4  0.406107 -0.119848 -0.459487 -0.564603 -0.869797 -0.120177  0.230116   \n",
       "\n",
       "          7         8         9  ...        41        42        43        44  \\\n",
       "0  0.570324 -0.183935  2.084440  ...  0.365105  0.222436  1.318043  0.170131   \n",
       "1 -1.260965  1.189414  0.048460  ...  0.002360 -0.424213 -0.030207 -0.585183   \n",
       "2 -0.495346  1.144418 -0.016699  ...  0.120182 -0.258227  0.045762  0.319787   \n",
       "3 -0.399794  1.280667  0.093377  ... -0.171234 -0.750394 -0.122897 -1.706450   \n",
       "4 -0.301367 -0.126521 -0.148975  ...  0.728755 -0.240772 -0.423331 -0.604241   \n",
       "\n",
       "         45        46        47        48        49  label  \n",
       "0  0.004944 -1.363862  1.034432 -0.596706  0.202156    1.0  \n",
       "1 -0.329262  0.881722  0.748271  1.373674 -0.160443    1.0  \n",
       "2 -0.150069  1.334856 -0.003443  0.180108  1.938359    1.0  \n",
       "3  0.137792 -0.465734 -0.720827 -0.416541 -0.985605    1.0  \n",
       "4  0.539562  0.392587  0.577998  0.489900  0.374064    1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=5\n",
    "\n",
    "# We select k random samples from our dataset, and divide them into num_folds disjoint sets of equal length\n",
    "indices = TRAIN_df.index.tolist()\n",
    "cv_dataset_indices = random.sample(population=indices, k=1000)\n",
    "cv_dataset = TRAIN_df.loc[cv_dataset_indices]\n",
    "cv_dataset = np.asarray(cv_dataset)\n",
    "cv = cross_validation_fold_split(dataset=cv_dataset, folds = num_folds)\n",
    "cv = np.asarray(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Decision Tree (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE CROSS VALIDATION RESULTS\n",
      "Cross Validation Split Shape:  (5, 200, 51)\n",
      "\n",
      "\n",
      "FEATURE_TYPES:\n",
      "\n",
      " 50 \n",
      "\n",
      "\n",
      "Accuracy for Test Fold:  0   0.735\n",
      "\n",
      "\n",
      "FEATURE_TYPES:\n",
      "\n",
      " 50 \n",
      "\n",
      "\n",
      "Accuracy for Test Fold:  1   0.78\n",
      "\n",
      "\n",
      "FEATURE_TYPES:\n",
      "\n",
      " 50 \n",
      "\n",
      "\n",
      "Accuracy for Test Fold:  2   0.73\n",
      "\n",
      "\n",
      "FEATURE_TYPES:\n",
      "\n",
      " 50 \n",
      "\n",
      "\n",
      "Accuracy for Test Fold:  3   0.77\n",
      "\n",
      "\n",
      "FEATURE_TYPES:\n",
      "\n",
      " 50 \n",
      "\n",
      "\n",
      "Accuracy for Test Fold:  4   0.77\n",
      "Cross Validation Accuracy:  0.757\n"
     ]
    }
   ],
   "source": [
    "# We then train our model(s) on num_folds-1 of the sets and evaluate on the final set (giving every set a chance to be the evaluation set)\n",
    "print(\"TREE CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=TRAIN_df, test_set_index=i)\n",
    "    cv_tree = decision_tree_algorithm(df=df_cv_train, ml_task='classification', max_depth=10)\n",
    "    \n",
    "    j = random_exclude(excluded=i, range_list=range(num_folds))\n",
    "    _, df_val = cross_validation_train_test_split(cv_set=cv, df=TRAIN_df, test_set_index=j)\n",
    "    cv_tree_pruned = post_pruning(cv_tree, df_cv_train, df_val, ml_task=\"classification\")\n",
    "    \n",
    "    accuracy = calculate_accuracy(df_cv_test, cv_tree)\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('Cross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RANDOM FOREST CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=TRAIN_df, test_set_index=i)\n",
    "    cv_forest = multiprocessor_random_forest_algorithm(train_df=df_cv_train, n_trees=50, n_bootstrap=180, n_features=9999, \n",
    "                                                tree_max_depth=10, ml_task='classification')\n",
    "    accuracy, predictions = calculate_forest_accuracy(df_cv_test, cv_forest)\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('\\n\\nCross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- WORD2VEC ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [traditions, merlot, features, grapes, differe...\n",
       "1       [deep, purple, color, layered, aromatics, blac...\n",
       "2       [beautiful, bottle, aged, aromas, revealing, f...\n",
       "3       [insoglio, del, cinghiale, foundation, wine, t...\n",
       "4       [black, cherry, cranberry, vanilla, roasting, ...\n",
       "                              ...                        \n",
       "1995    [estate, chardonnay, refreshing, crisp, floral...\n",
       "1996    [delle, venezie, italy, tre, region, made, thr...\n",
       "1997    [grown, hillside, santa, maria, bench, barbara...\n",
       "1998    [framed, light, lemony, acidity, vibrant, mine...\n",
       "1999    [popularity, demand, dry, riesling, sweet, tho...\n",
       "Name: description, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = filtered_df['description'].copy()\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wine corpus contains 87,333 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print('The wine corpus contains {0:,} tokens'.format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.word2vec as w2v\n",
    "\n",
    "num_features = 300\n",
    "min_word_count = 1\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 10\n",
    "downsampling = 1e-3\n",
    "seed=42\n",
    "\n",
    "wine2vec = w2v.Word2Vec(sg=1, seed=seed, workers=num_workers, size=num_features, min_count=min_word_count, window=context_size, sample=downsampling)\n",
    "wine2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 8510\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec vocabulary length:', len(wine2vec.wv.vocab))\n",
    "print(wine2vec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-43bd81550482>:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  wine2vec.train(sentences, total_examples=wine2vec.corpus_count, epochs=wine2vec.iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(401623, 436665)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine2vec.train(sentences, total_examples=wine2vec.corpus_count, epochs=wine2vec.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[-0.032882363, -0.015514586, -0.03601328, 0.0...\n",
       "1       [[-0.15854508, 0.30994657, 0.0013985692, -0.11...\n",
       "2       [[0.008912634, 0.2211171, 0.09175639, -0.06798...\n",
       "3       [[-0.015497052, -0.0043974225, -0.01539303, 0....\n",
       "4       [[-0.1530068, 0.33843523, 0.16195166, -0.07445...\n",
       "                              ...                        \n",
       "1995    [[-0.03134968, -0.01678482, -0.0066042803, -0....\n",
       "1996    [[-0.025455082, -0.006362297, -0.016307851, 0....\n",
       "1997    [[-0.032143537, -0.012416244, 0.006038067, -0....\n",
       "1998    [[-0.027692253, 0.31596544, 0.20393181, -0.036...\n",
       "1999    [[-0.03012332, -0.018497268, -0.037862334, 0.0...\n",
       "Name: description, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_vector(model, word):\n",
    "    return model.wv[word]\n",
    "\n",
    "df_new = filtered_df.copy()\n",
    "df_new['description'] = df_new['description'].transform(lambda x: [get_word_vector(model=wine2vec, word=word) for word in x])\n",
    "df_new['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 300 features for each description:\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       [-3.2449803, 9.214225, 0.38900614, -2.4666688,...\n",
       "1       [-2.4679615, 8.614912, 2.0543778, -1.1914982, ...\n",
       "2       [-2.1554103, 5.142528, 1.2000762, -0.8881511, ...\n",
       "3       [-2.9846292, 6.2345457, 0.2841835, -0.79096794...\n",
       "4       [-2.1482818, 10.142084, 3.112584, -1.9630648, ...\n",
       "                              ...                        \n",
       "1995    [-0.09059665, 0.59008676, 1.8152654, 1.9556797...\n",
       "1996    [-0.8923338, 4.583701, 3.9287446, 0.57219845, ...\n",
       "1997    [-1.8054626, 5.4407167, 3.1684525, -0.64351463...\n",
       "1998    [-0.5464104, 1.6006874, 1.8525207, 2.287367, -...\n",
       "1999    [-2.8178847, 3.8953316, 2.4202645, 0.9484857, ...\n",
       "Name: description, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('There are {} features for each description:\\n\\n'.format(df_new['description'].iloc[0][0].shape[0])) \n",
    "df_new['description']= [np.sum(df_new['description'].iloc[i], axis=0) for i in range(len(df_new['description']))]\n",
    "df_new['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: \n",
      "                                            description  label\n",
      "0     [-3.2449803, 9.214225, 0.38900614, -2.4666688,...      1\n",
      "1     [-2.4679615, 8.614912, 2.0543778, -1.1914982, ...      1\n",
      "3     [-2.9846292, 6.2345457, 0.2841835, -0.79096794...      1\n",
      "4     [-2.1482818, 10.142084, 3.112584, -1.9630648, ...      1\n",
      "5     [-1.7842454, 7.4831624, 0.5973474, -2.5305257,...      1\n",
      "...                                                 ...    ...\n",
      "1994  [-0.019414235, 7.5020313, 5.814876, 0.76685077...      0\n",
      "1995  [-0.09059665, 0.59008676, 1.8152654, 1.9556797...      0\n",
      "1997  [-1.8054626, 5.4407167, 3.1684525, -0.64351463...      0\n",
      "1998  [-0.5464104, 1.6006874, 1.8525207, 2.287367, -...      0\n",
      "1999  [-2.8178847, 3.8953316, 2.4202645, 0.9484857, ...      0\n",
      "\n",
      "[1400 rows x 2 columns] \n",
      "\n",
      " test_df: \n",
      "                                            description  label\n",
      "153   [-0.7823523, 6.136071, 0.8799547, -1.7928402, ...      1\n",
      "1333  [-0.7810608, 8.100519, 6.598667, -0.1386536, -...      0\n",
      "491   [-1.8584647, 10.046857, 4.071286, -1.5664798, ...      1\n",
      "1119  [0.32250336, 3.4684315, 1.6539122, -0.17690292...      0\n",
      "806   [-0.1391658, 5.298137, 0.80118567, -0.5470841,...      1\n",
      "...                                                 ...    ...\n",
      "90    [-1.7897897, 7.239999, 1.4507147, -1.6752238, ...      1\n",
      "652   [-2.2696242, 4.9046717, 0.46573195, -0.2697018...      1\n",
      "388   [-2.52659, 5.124529, -0.046213776, 0.7887775, ...      1\n",
      "899   [-0.6716698, 3.9138546, 2.199429, -0.4590978, ...      1\n",
      "942   [-1.466318, 6.8890185, 2.7878034, -1.0550432, ...      1\n",
      "\n",
      "[600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = df_new[['description', 'label']]\n",
    "\n",
    "train_df, test_df = train_test_split(df=df_new, test_size=0.3)\n",
    "print('train_df: \\n{}'.format(train_df), '\\n\\n', 'test_df: \\n{}'.format(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray([train_df.iloc[i][0] for i in range(len(train_df))])\n",
    "y=np.asarray(train_df.label).reshape(X.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=np.asarray([test_df.iloc[i][0] for i in range(len(test_df))])\n",
    "ytest=np.asarray(test_df.label).reshape(Xtest.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ -3.2449803 ,   9.214225  ,   0.38900614, ..., -14.482726  ,\n",
       "         -11.38087   ,  -7.6981416 ],\n",
       "        [ -2.4679615 ,   8.614912  ,   2.0543778 , ..., -10.133245  ,\n",
       "          -7.85954   ,  -5.5641994 ],\n",
       "        [ -2.9846292 ,   6.2345457 ,   0.2841835 , ..., -12.646857  ,\n",
       "          -9.072554  ,  -5.4624825 ],\n",
       "        ...,\n",
       "        [ -1.8054626 ,   5.4407167 ,   3.1684525 , ..., -10.309441  ,\n",
       "          -8.465744  ,  -5.362092  ],\n",
       "        [ -0.5464104 ,   1.6006874 ,   1.8525207 , ..., -10.3321495 ,\n",
       "          -8.065953  ,  -4.666677  ],\n",
       "        [ -2.8178847 ,   3.8953316 ,   2.4202645 , ..., -13.915132  ,\n",
       "         -11.083644  ,  -5.9618073 ]], dtype=float32),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400, 300), (1400, 1), (600, 300), (600, 1))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['_'+str(i)+'_' for i in range(0,300)]\n",
    "columns.append('target_label')\n",
    "D = pd.DataFrame(data=np.concatenate((X,y), axis=1), columns=columns)\n",
    "T = pd.DataFrame(data=np.concatenate((Xtest,ytest), axis=1), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(X, 'X')\n",
    "save_obj(y, 'y')\n",
    "save_obj(D, 'D')\n",
    "save_obj(T, 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, D, T = load_obj('X'), load_obj('y'), load_obj('D'), load_obj('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_0_</th>\n",
       "      <th>_1_</th>\n",
       "      <th>_2_</th>\n",
       "      <th>_3_</th>\n",
       "      <th>_4_</th>\n",
       "      <th>_5_</th>\n",
       "      <th>_6_</th>\n",
       "      <th>_7_</th>\n",
       "      <th>_8_</th>\n",
       "      <th>_9_</th>\n",
       "      <th>...</th>\n",
       "      <th>_291_</th>\n",
       "      <th>_292_</th>\n",
       "      <th>_293_</th>\n",
       "      <th>_294_</th>\n",
       "      <th>_295_</th>\n",
       "      <th>_296_</th>\n",
       "      <th>_297_</th>\n",
       "      <th>_298_</th>\n",
       "      <th>_299_</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.244980</td>\n",
       "      <td>9.214225</td>\n",
       "      <td>0.389006</td>\n",
       "      <td>-2.466669</td>\n",
       "      <td>-10.108183</td>\n",
       "      <td>-5.349817</td>\n",
       "      <td>3.663701</td>\n",
       "      <td>-6.674496</td>\n",
       "      <td>-3.192860</td>\n",
       "      <td>-0.020569</td>\n",
       "      <td>...</td>\n",
       "      <td>3.266598</td>\n",
       "      <td>-9.103728</td>\n",
       "      <td>10.761422</td>\n",
       "      <td>7.853642</td>\n",
       "      <td>-6.807631</td>\n",
       "      <td>-11.809257</td>\n",
       "      <td>-14.482726</td>\n",
       "      <td>-11.380870</td>\n",
       "      <td>-7.698142</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.467962</td>\n",
       "      <td>8.614912</td>\n",
       "      <td>2.054378</td>\n",
       "      <td>-1.191498</td>\n",
       "      <td>-4.495191</td>\n",
       "      <td>-3.291983</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>-5.222356</td>\n",
       "      <td>-3.280240</td>\n",
       "      <td>-0.862789</td>\n",
       "      <td>...</td>\n",
       "      <td>5.248476</td>\n",
       "      <td>-6.066744</td>\n",
       "      <td>3.794762</td>\n",
       "      <td>5.778044</td>\n",
       "      <td>-4.476419</td>\n",
       "      <td>-6.985113</td>\n",
       "      <td>-10.133245</td>\n",
       "      <td>-7.859540</td>\n",
       "      <td>-5.564199</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.984629</td>\n",
       "      <td>6.234546</td>\n",
       "      <td>0.284184</td>\n",
       "      <td>-0.790968</td>\n",
       "      <td>-7.697112</td>\n",
       "      <td>-4.354197</td>\n",
       "      <td>2.343929</td>\n",
       "      <td>-4.118157</td>\n",
       "      <td>-2.299702</td>\n",
       "      <td>-0.969656</td>\n",
       "      <td>...</td>\n",
       "      <td>3.313917</td>\n",
       "      <td>-8.509166</td>\n",
       "      <td>10.492888</td>\n",
       "      <td>7.616368</td>\n",
       "      <td>-4.438893</td>\n",
       "      <td>-10.610935</td>\n",
       "      <td>-12.646857</td>\n",
       "      <td>-9.072554</td>\n",
       "      <td>-5.462482</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.148282</td>\n",
       "      <td>10.142084</td>\n",
       "      <td>3.112584</td>\n",
       "      <td>-1.963065</td>\n",
       "      <td>-5.608982</td>\n",
       "      <td>-3.803071</td>\n",
       "      <td>-0.209855</td>\n",
       "      <td>-6.279403</td>\n",
       "      <td>-4.356566</td>\n",
       "      <td>-0.283045</td>\n",
       "      <td>...</td>\n",
       "      <td>5.195980</td>\n",
       "      <td>-6.178975</td>\n",
       "      <td>4.177288</td>\n",
       "      <td>6.340839</td>\n",
       "      <td>-4.801833</td>\n",
       "      <td>-7.717837</td>\n",
       "      <td>-10.322958</td>\n",
       "      <td>-9.140126</td>\n",
       "      <td>-6.472419</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.784245</td>\n",
       "      <td>7.483162</td>\n",
       "      <td>0.597347</td>\n",
       "      <td>-2.530526</td>\n",
       "      <td>-6.072765</td>\n",
       "      <td>-2.718414</td>\n",
       "      <td>2.127453</td>\n",
       "      <td>-4.741004</td>\n",
       "      <td>-1.905276</td>\n",
       "      <td>0.291880</td>\n",
       "      <td>...</td>\n",
       "      <td>2.386324</td>\n",
       "      <td>-4.541891</td>\n",
       "      <td>4.129561</td>\n",
       "      <td>4.933238</td>\n",
       "      <td>-4.609901</td>\n",
       "      <td>-6.064564</td>\n",
       "      <td>-7.777425</td>\n",
       "      <td>-6.084000</td>\n",
       "      <td>-4.322505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>-0.019414</td>\n",
       "      <td>7.502031</td>\n",
       "      <td>5.814876</td>\n",
       "      <td>0.766851</td>\n",
       "      <td>-3.070222</td>\n",
       "      <td>-3.554436</td>\n",
       "      <td>-3.886941</td>\n",
       "      <td>-3.782379</td>\n",
       "      <td>-5.996253</td>\n",
       "      <td>-2.069686</td>\n",
       "      <td>...</td>\n",
       "      <td>6.950454</td>\n",
       "      <td>-8.104604</td>\n",
       "      <td>7.740019</td>\n",
       "      <td>7.116932</td>\n",
       "      <td>-2.408879</td>\n",
       "      <td>-9.247143</td>\n",
       "      <td>-10.376175</td>\n",
       "      <td>-10.049765</td>\n",
       "      <td>-6.210229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>-0.090597</td>\n",
       "      <td>0.590087</td>\n",
       "      <td>1.815265</td>\n",
       "      <td>1.955680</td>\n",
       "      <td>-1.017433</td>\n",
       "      <td>-1.686828</td>\n",
       "      <td>-1.714668</td>\n",
       "      <td>-0.239967</td>\n",
       "      <td>-2.067820</td>\n",
       "      <td>-2.066956</td>\n",
       "      <td>...</td>\n",
       "      <td>2.653470</td>\n",
       "      <td>-5.235921</td>\n",
       "      <td>6.025311</td>\n",
       "      <td>2.179415</td>\n",
       "      <td>-1.323213</td>\n",
       "      <td>-4.543195</td>\n",
       "      <td>-5.856121</td>\n",
       "      <td>-4.781673</td>\n",
       "      <td>-2.858314</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>-1.805463</td>\n",
       "      <td>5.440717</td>\n",
       "      <td>3.168453</td>\n",
       "      <td>-0.643515</td>\n",
       "      <td>-6.843784</td>\n",
       "      <td>-2.577157</td>\n",
       "      <td>0.319431</td>\n",
       "      <td>-3.165191</td>\n",
       "      <td>-2.531389</td>\n",
       "      <td>-0.510012</td>\n",
       "      <td>...</td>\n",
       "      <td>2.706594</td>\n",
       "      <td>-8.551054</td>\n",
       "      <td>11.039748</td>\n",
       "      <td>7.269344</td>\n",
       "      <td>-2.962161</td>\n",
       "      <td>-9.371391</td>\n",
       "      <td>-10.309441</td>\n",
       "      <td>-8.465744</td>\n",
       "      <td>-5.362092</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>-0.546410</td>\n",
       "      <td>1.600687</td>\n",
       "      <td>1.852521</td>\n",
       "      <td>2.287367</td>\n",
       "      <td>-3.114530</td>\n",
       "      <td>-3.411109</td>\n",
       "      <td>-0.876414</td>\n",
       "      <td>-1.460925</td>\n",
       "      <td>-2.559625</td>\n",
       "      <td>-2.372160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.194547</td>\n",
       "      <td>-8.384384</td>\n",
       "      <td>10.655892</td>\n",
       "      <td>4.800525</td>\n",
       "      <td>-2.094435</td>\n",
       "      <td>-9.022962</td>\n",
       "      <td>-10.332150</td>\n",
       "      <td>-8.065953</td>\n",
       "      <td>-4.666677</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>-2.817885</td>\n",
       "      <td>3.895332</td>\n",
       "      <td>2.420264</td>\n",
       "      <td>0.948486</td>\n",
       "      <td>-8.213029</td>\n",
       "      <td>-4.021223</td>\n",
       "      <td>1.088651</td>\n",
       "      <td>-2.688962</td>\n",
       "      <td>-2.271796</td>\n",
       "      <td>-1.622371</td>\n",
       "      <td>...</td>\n",
       "      <td>2.684177</td>\n",
       "      <td>-11.370110</td>\n",
       "      <td>16.001041</td>\n",
       "      <td>8.693902</td>\n",
       "      <td>-3.242974</td>\n",
       "      <td>-12.533834</td>\n",
       "      <td>-13.915132</td>\n",
       "      <td>-11.083644</td>\n",
       "      <td>-5.961807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           _0_        _1_       _2_       _3_        _4_       _5_       _6_  \\\n",
       "0    -3.244980   9.214225  0.389006 -2.466669 -10.108183 -5.349817  3.663701   \n",
       "1    -2.467962   8.614912  2.054378 -1.191498  -4.495191 -3.291983  0.057604   \n",
       "2    -2.984629   6.234546  0.284184 -0.790968  -7.697112 -4.354197  2.343929   \n",
       "3    -2.148282  10.142084  3.112584 -1.963065  -5.608982 -3.803071 -0.209855   \n",
       "4    -1.784245   7.483162  0.597347 -2.530526  -6.072765 -2.718414  2.127453   \n",
       "...        ...        ...       ...       ...        ...       ...       ...   \n",
       "1395 -0.019414   7.502031  5.814876  0.766851  -3.070222 -3.554436 -3.886941   \n",
       "1396 -0.090597   0.590087  1.815265  1.955680  -1.017433 -1.686828 -1.714668   \n",
       "1397 -1.805463   5.440717  3.168453 -0.643515  -6.843784 -2.577157  0.319431   \n",
       "1398 -0.546410   1.600687  1.852521  2.287367  -3.114530 -3.411109 -0.876414   \n",
       "1399 -2.817885   3.895332  2.420264  0.948486  -8.213029 -4.021223  1.088651   \n",
       "\n",
       "           _7_       _8_       _9_  ...     _291_      _292_      _293_  \\\n",
       "0    -6.674496 -3.192860 -0.020569  ...  3.266598  -9.103728  10.761422   \n",
       "1    -5.222356 -3.280240 -0.862789  ...  5.248476  -6.066744   3.794762   \n",
       "2    -4.118157 -2.299702 -0.969656  ...  3.313917  -8.509166  10.492888   \n",
       "3    -6.279403 -4.356566 -0.283045  ...  5.195980  -6.178975   4.177288   \n",
       "4    -4.741004 -1.905276  0.291880  ...  2.386324  -4.541891   4.129561   \n",
       "...        ...       ...       ...  ...       ...        ...        ...   \n",
       "1395 -3.782379 -5.996253 -2.069686  ...  6.950454  -8.104604   7.740019   \n",
       "1396 -0.239967 -2.067820 -2.066956  ...  2.653470  -5.235921   6.025311   \n",
       "1397 -3.165191 -2.531389 -0.510012  ...  2.706594  -8.551054  11.039748   \n",
       "1398 -1.460925 -2.559625 -2.372160  ...  4.194547  -8.384384  10.655892   \n",
       "1399 -2.688962 -2.271796 -1.622371  ...  2.684177 -11.370110  16.001041   \n",
       "\n",
       "         _294_     _295_      _296_      _297_      _298_     _299_  \\\n",
       "0     7.853642 -6.807631 -11.809257 -14.482726 -11.380870 -7.698142   \n",
       "1     5.778044 -4.476419  -6.985113 -10.133245  -7.859540 -5.564199   \n",
       "2     7.616368 -4.438893 -10.610935 -12.646857  -9.072554 -5.462482   \n",
       "3     6.340839 -4.801833  -7.717837 -10.322958  -9.140126 -6.472419   \n",
       "4     4.933238 -4.609901  -6.064564  -7.777425  -6.084000 -4.322505   \n",
       "...        ...       ...        ...        ...        ...       ...   \n",
       "1395  7.116932 -2.408879  -9.247143 -10.376175 -10.049765 -6.210229   \n",
       "1396  2.179415 -1.323213  -4.543195  -5.856121  -4.781673 -2.858314   \n",
       "1397  7.269344 -2.962161  -9.371391 -10.309441  -8.465744 -5.362092   \n",
       "1398  4.800525 -2.094435  -9.022962 -10.332150  -8.065953 -4.666677   \n",
       "1399  8.693902 -3.242974 -12.533834 -13.915132 -11.083644 -5.961807   \n",
       "\n",
       "      target_label  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              1.0  \n",
       "...            ...  \n",
       "1395           0.0  \n",
       "1396           0.0  \n",
       "1397           0.0  \n",
       "1398           0.0  \n",
       "1399           0.0  \n",
       "\n",
       "[1400 rows x 301 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=5\n",
    "\n",
    "# We select k random samples from our dataset, and divide them into num_folds disjoint sets of equal length\n",
    "indices = D.index.tolist()\n",
    "cv_dataset_indices = random.sample(population=indices, k=500)\n",
    "cv_dataset = D.loc[cv_dataset_indices]\n",
    "cv_dataset = np.asarray(cv_dataset)\n",
    "cv = cross_validation_fold_split(dataset=cv_dataset, folds = num_folds)\n",
    "cv = np.asarray(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SINGLE DECISION TREE (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE CROSS VALIDATION RESULTS\n",
      "Cross Validation Split Shape:  (5, 100, 301)\n",
      "Accuracy for Test Fold:  0   0.97\n",
      "Accuracy for Test Fold:  1   0.93\n",
      "Accuracy for Test Fold:  2   0.89\n",
      "Accuracy for Test Fold:  3   0.97\n",
      "Accuracy for Test Fold:  4   0.95\n",
      "Cross Validation Accuracy:  0.942\n"
     ]
    }
   ],
   "source": [
    "# We then train our model(s) on num_folds-1 of the sets and evaluate on the final set (giving every set a chance to be the evaluation set)\n",
    "print(\"TREE CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=D, test_set_index=i)\n",
    "    cv_tree = decision_tree_algorithm(df=df_cv_train, ml_task='classification', max_depth=10)\n",
    "    \n",
    "    j = random_exclude(excluded=i, range_list=range(num_folds))\n",
    "    _, df_val = cross_validation_train_test_split(cv_set=cv, df=D, test_set_index=j)\n",
    "    cv_tree_pruned = post_pruning(cv_tree, df_cv_train, df_val, ml_task=\"classification\")\n",
    "    \n",
    "    accuracy = calculate_accuracy(df_cv_test, cv_tree_pruned)\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('Cross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_90_ <= 0.859322726726532': [{'_135_ <= -0.2206837236881256': [0.0,\n",
       "    {'_135_ <= 0.32357239723205566': [{'_75_ <= 0.6699714660644531': [1.0,\n",
       "        0.0]},\n",
       "      1.0]}]},\n",
       "  1.0]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_tree_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CROSS VALIDATION RESULTS\n",
      "Cross Validation Split Shape:  (5, 100, 301)\n",
      "\n",
      "Time taken to build and prune forest = 556.6860954761505 seconds\n",
      "\n",
      "Forest contains: 50 trees\n",
      "precision: \t 0.98\n",
      "recall: \t 0.98\n",
      "fscore: \t 0.98\n",
      "support:\t None\n",
      "Accuracy for Test Fold:  0   0.98\n",
      "\n",
      "Time taken to build and prune forest = 412.11194109916687 seconds\n",
      "\n",
      "Forest contains: 50 trees\n",
      "precision: \t 0.9502403846153845\n",
      "recall: \t 0.95\n",
      "fscore: \t 0.9500250626566417\n",
      "support:\t None\n",
      "Accuracy for Test Fold:  1   0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-82:\n",
      "Process ForkPoolWorker-146:\n",
      "Process ForkPoolWorker-52:\n",
      "Process ForkPoolWorker-98:\n",
      "Process ForkPoolWorker-85:\n",
      "Process ForkPoolWorker-103:\n",
      "Process ForkPoolWorker-92:\n",
      "Process ForkPoolWorker-101:\n",
      "Process ForkPoolWorker-148:\n",
      "Process ForkPoolWorker-113:\n",
      "Process ForkPoolWorker-105:\n",
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-138:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-117:\n",
      "Process ForkPoolWorker-116:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-100:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-91:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-62:\n",
      "Process ForkPoolWorker-134:\n",
      "Process ForkPoolWorker-68:\n",
      "Process ForkPoolWorker-70:\n",
      "Process ForkPoolWorker-46:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-42:\n",
      "Process ForkPoolWorker-126:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-54:\n",
      "Process ForkPoolWorker-39:\n",
      "Process ForkPoolWorker-133:\n",
      "Process ForkPoolWorker-114:\n",
      "Process ForkPoolWorker-145:\n",
      "Process ForkPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-94:\n",
      "Process ForkPoolWorker-106:\n",
      "Process ForkPoolWorker-143:\n",
      "Process ForkPoolWorker-87:\n",
      "Process ForkPoolWorker-49:\n",
      "Process ForkPoolWorker-78:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-108:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-47:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-149:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-43:\n",
      "Process ForkPoolWorker-41:\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-104:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-139:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-128:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-48:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-111:\n",
      "Process ForkPoolWorker-110:\n",
      "Process ForkPoolWorker-50:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-115:\n",
      "Process ForkPoolWorker-137:\n",
      "Process ForkPoolWorker-140:\n",
      "Process ForkPoolWorker-130:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-121:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-59:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-141:\n",
      "Process ForkPoolWorker-77:\n",
      "Process ForkPoolWorker-132:\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-112:\n",
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-69:\n",
      "Process ForkPoolWorker-75:\n",
      "Process ForkPoolWorker-150:\n",
      "Process ForkPoolWorker-66:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-95:\n",
      "Process ForkPoolWorker-147:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-89:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-144:\n",
      "Process ForkPoolWorker-124:\n",
      "Process ForkPoolWorker-135:\n",
      "Process ForkPoolWorker-81:\n",
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-129:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-123:\n",
      "Process ForkPoolWorker-65:\n",
      "Process ForkPoolWorker-7:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8ed01184c1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf_cv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cv_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     cv_forest = multiprocessor_random_forest_algorithm(train_df=df_cv_train, n_trees=50, n_bootstrap=175, n_features=9999, \n\u001b[0;32m----> 8\u001b[0;31m                                                 tree_max_depth=10, ml_task='classification')\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_forest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cv_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for Test Fold: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random_forest.py\u001b[0m in \u001b[0;36mmultiprocessor_random_forest_algorithm\u001b[0;34m(train_df, n_trees, n_bootstrap, n_features, tree_max_depth, ml_task)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_max_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mforest_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiprocessor_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTime taken to build and prune forest = {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_max_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mforest_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiprocessor_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTime taken to build and prune forest = {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mPool\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mrunning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         '''\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-127:\n",
      "Process ForkPoolWorker-119:\n",
      "Process ForkPoolWorker-136:\n",
      "Process ForkPoolWorker-53:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-84:\n",
      "Process ForkPoolWorker-97:\n",
      "Process ForkPoolWorker-80:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-99:\n",
      "Process ForkPoolWorker-131:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-142:\n",
      "Process ForkPoolWorker-83:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-71:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-107:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-122:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-93:\n",
      "Process ForkPoolWorker-96:\n",
      "Process ForkPoolWorker-120:\n",
      "Process ForkPoolWorker-125:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-118:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-90:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-74:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=D, test_set_index=i)\n",
    "    cv_forest = multiprocessor_random_forest_algorithm(train_df=df_cv_train, n_trees=50, n_bootstrap=175, n_features=9999, \n",
    "                                                tree_max_depth=10, ml_task='classification')\n",
    "    accuracy, predictions = calculate_forest_accuracy(df_cv_test, cv_forest, ml_task=\"classification\")\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('\\n\\nCross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for description in filtered_df['description']:\n",
    "    for token in description:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(vocabulary, 'GC_SET2_BoW_WineVocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of wine vocabulary: 8510 \n",
      "\n",
      " Random Sample of Vocabulary: \n",
      "['packs', 'myriad', 'trave', 'moka', 'another years', 'jewel', 'rightly', 'king', 'verona', 'trays', 'january', 'pouring', 'botanical', 'attractively', 'sperss', 'climatic', 'induced', 'seghesio', 'seventh', 'formally', 'crack', 'medley', 'airing', 'flushes', 'vegtables', 'plantings', 'casablanca', 'implement', 'aggressive', 'sumptuous', 'barbeques', 'sports', 'impeccable', 'livio', 'felluga', 'vertigo', 'currange', 'ready drink', 'flores', 'zuccardi', 'bluish', 'comparable', 'georges', 'normally', 'versions', 'arcus', 'confectionary', 'mulling', 'succulence', 'persisting', 'tartare', 'cassoulet', 'rabbit', 'responsible', 'piluna', 'scrub', 'underneath', 'turns', 'patton', 'pantry', 'loamy', 'quietly', 'fails', 'regarded', 'aperitif', 'wafting', 'mildly', 'stuff', 'breathes', 'folks', 'impatient', 'cream sauces', 'wadenswil', 'overlays', 'assertive', 'inkwell', 'bottom', 'brewed', 'teenager', 'talk']\n"
     ]
    }
   ],
   "source": [
    "start = random.randint(0, len(vocabulary)-81)\n",
    "end = start + 80\n",
    "vocab_sample = vocabulary[start:end]\n",
    "print('Length of wine vocabulary: {}'.format(len(vocabulary)), '\\n\\n', 'Random Sample of Vocabulary: \\n{}'.format(vocab_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the counts and a dictionary to store feature word synonyms\n",
    "dict_count = {}\n",
    "dict_syns = {}\n",
    "            \n",
    "# Find synonyms of feature words and store them in dict_syns\n",
    "for word in vocabulary:\n",
    "    dict_syns[word] = []\n",
    "    dict_syns[word].append(word)\n",
    "    for syn in wn.synsets(word):\n",
    "        for lem in syn.lemmas():\n",
    "            if lem.name().replace('_', ' ').lower() not in dict_syns[word]:\n",
    "                dict_syns[word].append(lem.name().replace('_', ' ').lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(dict_syns, 'GC_SET2_BoW_DictSynonyms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_array = np.asarray(filtered_df['description'])              \n",
    "for word in dict_syns.keys():\n",
    "    dict_count[word] = 0\n",
    "    #Note that the descriptions stored in filtered_df are already tokenized\n",
    "    for description in descriptions_array: \n",
    "        for i in range(len(dict_syns[word])):\n",
    "            if dict_syns[word][i] in description:\n",
    "                dict_count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(dict_count, 'GC_SET2_BoW_DictCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of wine count dictionary: 8510 \n",
      "\n",
      " Random Sample of count dicti: \n",
      "[('packs', 77), ('myriad', 4), ('trave', 1), ('moka', 1), ('another years', 4), ('jewel', 5), ('rightly', 2), ('king', 40), ('verona', 1), ('trays', 1), ('january', 3), ('pouring', 10), ('botanical', 1), ('attractively', 73), ('sperss', 1), ('climatic', 1), ('induced', 81), ('seghesio', 1), ('seventh', 1), ('formally', 3), ('crack', 75), ('medley', 3), ('airing', 17), ('flushes', 253), ('vegtables', 1), ('plantings', 43), ('casablanca', 5), ('implement', 8), ('aggressive', 5), ('sumptuous', 54), ('barbeques', 8), ('sports', 13), ('impeccable', 2), ('livio', 1), ('felluga', 1), ('vertigo', 1), ('currange', 1), ('ready drink', 7), ('flores', 1), ('zuccardi', 2), ('bluish', 38), ('comparable', 115), ('georges', 2), ('normally', 4), ('versions', 11), ('arcus', 1), ('confectionary', 2), ('mulling', 5), ('succulence', 6), ('persisting', 23), ('tartare', 1), ('cassoulet', 1), ('rabbit', 3), ('responsible', 1), ('piluna', 1), ('scrub', 4), ('underneath', 1), ('turns', 283), ('patton', 1), ('pantry', 11), ('loamy', 1), ('quietly', 10), ('fails', 48), ('regarded', 17), ('aperitif', 67), ('wafting', 2), ('mildly', 14), ('stuff', 19), ('breathes', 6), ('folks', 31), ('impatient', 1), ('cream sauces', 7), ('wadenswil', 1), ('overlays', 2), ('assertive', 5), ('inkwell', 1), ('bottom', 85), ('brewed', 1), ('teenager', 1), ('talk', 426)]\n"
     ]
    }
   ],
   "source": [
    "dict_count_sample = [(key,value) for key,value in dict_count.items() if key in vocab_sample]\n",
    "print('Length of wine count dictionary: {}'.format(len(dict_count)), '\\n\\n', 'Random Sample of count dicti: \\n{}'.format(dict_count_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(filtered_df['label'])\n",
    "descriptions = np.asarray(filtered_df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0] (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(labels, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]] \n",
      " (2000, 8511)\n"
     ]
    }
   ],
   "source": [
    "# OneHot encode our feature words for the model\n",
    "feature_matrix = np.empty((len(labels), len(vocabulary)))\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(vocabulary)):\n",
    "        for k in dict_syns[vocabulary[j]]:\n",
    "            if k in descriptions[i]:\n",
    "                feature_matrix[i, j] = 1\n",
    "\n",
    "feature_matrix = np.concatenate((feature_matrix, labels.reshape(feature_matrix.shape[0], 1)), axis=1)\n",
    "print(feature_matrix, '\\n', feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(feature_matrix, 'GC_SET2_BoW_FeatureMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_syns = load_obj('GC_SET2_BoW_DictSynonyms')\n",
    "dict_count = load_obj('GC_SET2_BoW_DictCount')\n",
    "vocabulary = load_obj('GC_SET2_BoW_WineVocabulary')\n",
    "feature_matrix = load_obj('GC_SET2_BoW_FeatureMatrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traditions</th>\n",
       "      <th>merlot</th>\n",
       "      <th>features</th>\n",
       "      <th>grapes</th>\n",
       "      <th>different</th>\n",
       "      <th>sites</th>\n",
       "      <th>columbia</th>\n",
       "      <th>valley</th>\n",
       "      <th>diversity</th>\n",
       "      <th>terroir</th>\n",
       "      <th>...</th>\n",
       "      <th>market</th>\n",
       "      <th>homerun</th>\n",
       "      <th>proposition</th>\n",
       "      <th>crave</th>\n",
       "      <th>revival</th>\n",
       "      <th>rising</th>\n",
       "      <th>ashes</th>\n",
       "      <th>artwork</th>\n",
       "      <th>portraying</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      traditions  merlot  features  grapes  different  sites  columbia  \\\n",
       "0            1.0     1.0       1.0     1.0        1.0    1.0       1.0   \n",
       "1            0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "2            0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "3            0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "4            0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "...          ...     ...       ...     ...        ...    ...       ...   \n",
       "1995         0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "1996         0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "1997         0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "1998         0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "1999         0.0     0.0       0.0     0.0        0.0    0.0       0.0   \n",
       "\n",
       "      valley  diversity  terroir  ...  market  homerun  proposition  crave  \\\n",
       "0        1.0        1.0      1.0  ...     0.0      0.0          0.0    0.0   \n",
       "1        0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "2        0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "3        0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "4        0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "...      ...        ...      ...  ...     ...      ...          ...    ...   \n",
       "1995     0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "1996     0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "1997     0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "1998     0.0        0.0      0.0  ...     0.0      0.0          0.0    0.0   \n",
       "1999     0.0        0.0      0.0  ...     1.0      1.0          1.0    1.0   \n",
       "\n",
       "      revival  rising  ashes  artwork  portraying  target_label  \n",
       "0         0.0     0.0    0.0      0.0         0.0           1.0  \n",
       "1         0.0     0.0    0.0      0.0         0.0           1.0  \n",
       "2         0.0     0.0    0.0      0.0         0.0           1.0  \n",
       "3         0.0     0.0    0.0      0.0         0.0           1.0  \n",
       "4         0.0     0.0    0.0      0.0         0.0           1.0  \n",
       "...       ...     ...    ...      ...         ...           ...  \n",
       "1995      0.0     0.0    0.0      0.0         0.0           0.0  \n",
       "1996      0.0     0.0    0.0      0.0         0.0           0.0  \n",
       "1997      0.0     0.0    0.0      0.0         0.0           0.0  \n",
       "1998      0.0     0.0    0.0      0.0         0.0           0.0  \n",
       "1999      1.0     1.0    1.0      1.0         1.0           0.0  \n",
       "\n",
       "[2000 rows x 8511 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = vocabulary\n",
    "columns.append('target_label')\n",
    "BoW_df = pd.DataFrame(data=feature_matrix, columns=columns)\n",
    "BoW_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN, TEST = train_test_split(df=BoW_df, test_size=0.3)\n",
    "save_obj(TRAIN, 'TRAIN_BoW_WINEMAKER_DATASET')\n",
    "save_obj(TEST, 'TEST_BoW_WINEMAKER_DATASET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=5\n",
    "\n",
    "# We select k random samples from our dataset, and divide them into num_folds disjoint sets of equal length\n",
    "indices = TRAIN.index.tolist()\n",
    "cv_dataset_indices = random.sample(population=indices, k=500)\n",
    "cv_dataset = TRAIN.loc[cv_dataset_indices]\n",
    "cv_dataset = np.asarray(cv_dataset)\n",
    "cv = cross_validation_fold_split(dataset=cv_dataset, folds = num_folds)\n",
    "cv = np.asarray(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SINGLE TREE (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE CROSS VALIDATION RESULTS\n",
      "Cross Validation Split Shape:  (5, 100, 8511)\n",
      "Accuracy for Test Fold:  0   0.91\n",
      "Accuracy for Test Fold:  1   0.94\n",
      "Accuracy for Test Fold:  2   0.93\n",
      "Accuracy for Test Fold:  3   0.95\n",
      "Accuracy for Test Fold:  4   0.98\n",
      "Cross Validation Accuracy:  0.9420000000000002\n"
     ]
    }
   ],
   "source": [
    "# We then train our model(s) on num_folds-1 of the sets and evaluate on the final set (giving every set a chance to be the evaluation set)\n",
    "print(\"TREE CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=TRAIN, test_set_index=i)\n",
    "    cv_tree = decision_tree_algorithm(df=df_cv_train, ml_task='classification', max_depth=10)\n",
    "    \n",
    "    j = random_exclude(excluded=i, range_list=range(num_folds))\n",
    "    _, df_val = cross_validation_train_test_split(cv_set=cv, df=TRAIN, test_set_index=j)\n",
    "    cv_tree_pruned = post_pruning(cv_tree, df_cv_train, df_val, ml_task=\"classification\")\n",
    "    \n",
    "    accuracy = calculate_accuracy(df_cv_test, cv_tree_pruned)\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('Cross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black = 1.0': [1.0,\n",
       "  {'crimson = 1.0': [{'apples = 1.0': [0.0,\n",
       "      {'grapefruits = 1.0': [0.0, 1.0]}]},\n",
       "    {'cabernets = 1.0': [1.0,\n",
       "      {'tannins = 1.0': [1.0,\n",
       "        {'syrah = 1.0': [1.0,\n",
       "          {'blueberry = 1.0': [1.0,\n",
       "            {'nobility = 1.0': [1.0,\n",
       "              {'cherries = 1.0': [1.0,\n",
       "                {'winemaking = 1.0': [{'tonic = 1.0': [0.0, 1.0]},\n",
       "                  0.0]}]}]}]}]}]}]}]}]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_tree_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST (PRUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RANDOM FOREST CROSS VALIDATION RESULTS\")\n",
    "print('Cross Validation Split Shape: ', cv.shape)\n",
    "\n",
    "total_accuracy = 0\n",
    "for i in range(num_folds):\n",
    "    df_cv_train, df_cv_test = cross_validation_train_test_split(cv_set=cv, df=D, test_set_index=i)\n",
    "    cv_forest = multiprocessor_random_forest_algorithm(train_df=df_cv_train, n_trees=50, n_bootstrap=175, n_features=9999, \n",
    "                                                tree_max_depth=10, ml_task='classification')\n",
    "    accuracy, predictions = calculate_forest_accuracy(df_cv_test, cv_forest, ml_task=\"classification\")\n",
    "    print(\"Accuracy for Test Fold: \", i, \" \", accuracy)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "cv_accuracy = total_accuracy/num_folds\n",
    "print('\\n\\nCross Validation Accuracy: ', cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
